{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# On the Objective Functions\n",
    "### 1. Context\n",
    "\n",
    "Given:\n",
    "\\begin{align}\n",
    "Z &= \\begin{bmatrix}\n",
    "z_{1, 1} & z_{1, 2} & \\dots & z_{1, N} \\\\\n",
    "z_{2, 1} & z_{2, 2} & \\dots & z_{2, N} \\\\\n",
    "z_{3, 1} & z_{3, 2} & \\dots & z_{3, N} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "z_{T, 1} & z_{t, 2} & \\dots & z_{T, N} \\\\\n",
    "\\end{bmatrix}_{T \\times N, T >> N} \\\\\n",
    "\\Sigma & \\equiv Z^{T}Z\\\\\n",
    "\\Sigma &= V\\Lambda V^{T} \\\\\n",
    "V^{T} V &= I \\\\\n",
    "\\Lambda &= \\begin{bmatrix}\n",
    "\\lambda_{1} & 0 & \\dots & 0 \\\\\n",
    "0 & \\lambda_{2} & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\dots & \\lambda_{N} \\\\\n",
    "\\end{bmatrix}_{N \\times N} \\\\\n",
    "V &= \\begin{bmatrix}\n",
    "v_{1, 1} & v_{1, 2} & \\dots & v_{1, N} \\\\\n",
    "v_{2, 1} & v_{2, 2} & \\dots & v_{2, N} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "v_{N, 1} & v_{N, 2} & \\dots & v_{N, N} \\\\\n",
    "\\end{bmatrix}_{N \\times N}\n",
    "\\end{align}\n",
    "\n",
    "We want to find the vector $x$ that maximizes following problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\max_{x} \\eta(x)\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "\\eta (x) & \\equiv \\exp \\left( -\\sum^{N}_{j=1} \\theta_{j} \\ln{(\\theta_{j})} \\right)\n",
    "\\end{align}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "\\theta = diag\\left(V^{T} x\\right) \\Lambda V^{T} x = \\begin{bmatrix}\n",
    "\\lambda_{1} \\left( \\sum^{N}_{i=1} x_{i}v_{i, 1}\\right)^{2} \\\\\n",
    "\\lambda_{2} \\left( \\sum^{N}_{i=1} x_{i}v_{i, 2}\\right)^{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\lambda_{N} \\left( \\sum^{N}_{i=1} x_{i}v_{i, N}\\right)^{2}  \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "When $\\theta$ is normalized so that $\\sum_{i=1}^{N} \\theta = 1$, $\\eta(x)$ is equivalent to the exponential of Shannon's entropy, which is maximized the $\\forall \\theta_{i}=\\theta_{j}$, in which case $\\eta (x) = N$.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Data\n",
    "I am using random mock data here, just to illustrate the point."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma Matrix:\n",
      " [[ 1.         -0.11755444 -0.12899818  0.13803969]\n",
      " [-0.11755444  1.          0.04437275 -0.1593243 ]\n",
      " [-0.12899818  0.04437275  1.         -0.06812091]\n",
      " [ 0.13803969 -0.1593243  -0.06812091  1.        ]]\n",
      "\n",
      "Lambda Matrix:\n",
      " [[1.33530476 0.         0.         0.        ]\n",
      " [0.         0.98157024 0.         0.        ]\n",
      " [0.         0.         0.84617325 0.        ]\n",
      " [0.         0.         0.         0.83695175]]\n",
      "\n",
      "V Matrix:\n",
      " [[ 0.54919594 -0.23416764  0.7219862  -0.3496931 ]\n",
      " [-0.50220562 -0.49379785  0.47665858  0.52607015]\n",
      " [-0.38818193  0.76968629  0.49717214 -0.09857826]\n",
      " [ 0.54358819  0.33001852  0.06597268  0.76892604]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import random_correlation\n",
    "import scipy.linalg\n",
    "from scipy.optimize import minimize\n",
    "import itertools\n",
    "\n",
    "seed = 0\n",
    "\n",
    "N = 4  # Number of columns of Z\n",
    "np.random.seed(seed)\n",
    "l = np.random.exponential(size=4)  # Eigenvectors of ZtZ = Sigma\n",
    "l = l * 4 / l.sum()\n",
    "l.sort()\n",
    "l = l[::-1]\n",
    "\n",
    "# Sigma Matrix\n",
    "Sigma = random_correlation.rvs(\n",
    "    eigs=l,\n",
    "    random_state=np.random.default_rng(seed=seed)\n",
    ")\n",
    "\n",
    "# Eigen-decomposition of Sigma\n",
    "Lambda, V = np.linalg.eig(Sigma)\n",
    "sort = Lambda.argsort()[::-1]\n",
    "Lambda = Lambda[sort]\n",
    "Lambda = np.diag(Lambda)\n",
    "V = V[:, sort]\n",
    "\n",
    "print('Sigma Matrix:\\n', Sigma)\n",
    "print('\\nLambda Matrix:\\n', Lambda)\n",
    "print('\\nV Matrix:\\n', V)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Set of possible solutions\n",
    "\n",
    "Given that we know that the problem above achieve its maximum when $\\forall \\theta_{i}=\\theta_{j}$, the problem has a closed form solution (when unconstrained):\n",
    "\n",
    "\\begin{align}\n",
    "\\theta &= \\boldsymbol{1}_{N} \\\\\n",
    "diag\\left(V^{T} x\\right) \\Lambda V^{T} x  &= \\boldsymbol{1}_{N}\\\\\n",
    "\\Lambda^{\\frac{1}{2}}V^{T} x &= \\boldsymbol{1}_{N} \\\\\n",
    "x^{\\star} &\\propto V \\Lambda^{-\\frac{1}{2}} \\boldsymbol{1}_{N}\n",
    "\\end{align}\n",
    "\n",
    "For a given $\\Sigma$, there are $2^{N-1}$ solution vectors ($x$) that can yield  $\\eta(w)=N$. This is due to the irrelevance of each eigen-vector's sign in the projection. The set of solutions $X_{N \\times 2^{N-1}}$ that spans all the possible linear transformations that result in $\\eta(w)=N$ is given by:\n",
    "\n",
    "\\begin{align}\n",
    "X \\propto V \\Lambda^{-\\frac{1}{2}}J\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "J = \\begin{bmatrix}\n",
    "\\mid & \\mid &  & \\mid \\\\\n",
    "j_{1} & j_{2} & \\dots & j_{2^{N-1}} \\\\\n",
    "\\mid & \\mid &  & \\mid \\\\\n",
    "\\end{bmatrix}_{N \\times 2^{N-1}}\n",
    "\\end{align}\n",
    "\n",
    "Where each $j_{i}$ is a vector with entries 1 and -1 as entries that change the sign of each eigenvector, and together all $j$ span every possible combination of signs.\n",
    "\n",
    "The set of possible 16 solutions is shown below:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of possible solutions:\n",
      "\n",
      "Sol 1: [0.18918188 0.04723977 0.25763433 0.50594402]\n",
      "Sol 2: [ 0.91295759 -0.64274167  0.70722586  0.02255822]\n",
      "Sol 3: [ 2.11268329  1.99422041  0.47178804 -3.57869174]\n",
      "Sol 4: [ 0.07148115  0.88465389 -0.00359226  0.04745722]\n",
      "Sol 5: [ 0.42195144  0.4381465  -0.25753692  0.39743898]\n",
      "Sol 6: [ 2.37920012  0.0088052  -0.58833058 -0.79967474]\n",
      "Sol 7: [ 0.38283854 -0.10142072  1.48014358 -0.7615614 ]\n",
      "Sol 8: [-0.10161337  0.33852487  0.50825721  0.25483129]\n",
      "Sol 9: [-0.10161337  0.33852487  0.50825721  0.25483129]\n",
      "Sol 10: [ 0.38283854 -0.10142072  1.48014358 -0.7615614 ]\n",
      "Sol 11: [ 2.37920012  0.0088052  -0.58833058 -0.79967474]\n",
      "Sol 12: [ 0.42195144  0.4381465  -0.25753692  0.39743898]\n",
      "Sol 13: [ 0.07148115  0.88465389 -0.00359226  0.04745722]\n",
      "Sol 14: [ 2.11268329  1.99422041  0.47178804 -3.57869174]\n",
      "Sol 15: [ 0.91295759 -0.64274167  0.70722586  0.02255822]\n",
      "Sol 16: [0.18918188 0.04723977 0.25763433 0.50594402]\n"
     ]
    }
   ],
   "source": [
    "combinations = [np.reshape(np.array(i), (N, 1)) for i in itertools.product([1, -1], repeat=N)]\n",
    "J = np.concatenate(combinations, axis=1)\n",
    "X = V @ np.linalg.inv(np.sqrt(Lambda)) @ J\n",
    "X = np.divide(X, X.sum(axis=0))\n",
    "\n",
    "print('Set of possible solutions:\\n')\n",
    "for i in range(X.shape[1]):\n",
    "    print(f'Sol {i + 1}:', X[:, i])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Original optimization problem\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\max_{x} \\hspace{1em} \\exp \\left( -\\sum^{N}_{j=1} \\theta_{j} \\ln{(\\theta_{j})} \\right)\n",
    "\\end{align}\n",
    "\n",
    "The solution given by the code below is one of the columns in the set of solutions. The function, when evaluated, yields N."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [ 2.11268298  1.99422014  0.47178802 -3.57869114]\n",
      "eval -3.9999999999999973\n"
     ]
    }
   ],
   "source": [
    "def original_objfunc(x, Lambda, V):\n",
    "    w = x.reshape(-1, 1)\n",
    "    theta = np.diag((V.T @ w).flatten()) @ Lambda @ V.T @ w\n",
    "    theta_norm = np.divide(theta.flatten(), theta.sum())  # Normalize the vector so it adds up to 1\n",
    "    val = -np.exp(-np.sum(np.multiply(theta_norm, np.log(theta_norm))))\n",
    "    return val\n",
    "\n",
    "opti = minimize(\n",
    "    fun=original_objfunc,\n",
    "    x0=np.array([1 / N] * N),\n",
    "    args=(Lambda, V),\n",
    "    method='SLSQP',\n",
    "    options={'maxiter': 1E9, 'ftol': 1E-14}\n",
    ")\n",
    "\n",
    "print('x: ', opti.x / opti.x.sum())\n",
    "print('eval', original_objfunc(opti.x, Lambda, V))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Alternative optimization problem\n",
    "\n",
    "\\begin{align}\n",
    "\\arg \\min_{x} \\hspace{1em} \\sum_{j=1}^{N} \\left( \\theta_{j}  - c\\right)^{2}\n",
    "\\end{align}\n",
    "\n",
    "where $c$ is a given constant.\n",
    "\n",
    "The solution given by the code below also is one of the columns in the set of solutions. The function, when evaluated, yields N.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [0.18918188 0.04723977 0.25763433 0.50594402]\n",
      "eval -3.999999999999999\n"
     ]
    }
   ],
   "source": [
    "def alternative_objfunc(x, Lambda, V, constant):\n",
    "    w = x.reshape(-1, 1)\n",
    "    theta = np.diag((V.T @ w).flatten()) @ Lambda @ V.T @ w\n",
    "    c = constant * np.ones(shape=(len(x), 1))\n",
    "    val = (theta - c).T @ (theta - c)\n",
    "    return val.item()\n",
    "\n",
    "opti = minimize(\n",
    "    fun=alternative_objfunc,\n",
    "    x0=np.array([1 / N] * N),\n",
    "    args=(Lambda, V, 1),\n",
    "    method='SLSQP',\n",
    "    options={'maxiter': 1E9, 'ftol': 1E-14}\n",
    ")\n",
    "\n",
    "print('x: ', opti.x / opti.x.sum())\n",
    "print('eval', original_objfunc(opti.x, Lambda, V))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}